# torchrun --nnodes 1 --nproc-per-node 8 -m apps.offline_inf.inference config=apps/offline_inf/configs/inference.yaml
name: "debug_evals"
stage: inference # preliminary for test normal usage: inference 
dump_dir:  /jfs/jinjie/code/downloads/dump/test_inference # change dir
parque_size: 4096
prefix_mapping:
  "text_embedding": "LLAMA3_3B_text_embedding"
  "latent_code": "HunyuanVideo_latent_code"
source_data:
  - stage: inference
    id: 0
    task: text_to_image
    data_name: cc12m
    source: mongodb
    batch_size: 256
    image_size: 256
    num_workers: 16
    # For 100000 samples, 8 GPUs 1 node, 930G RAM used in the node before launch data loader:
    # 16 worker: 130 secs and +200G RAM for init, 6.1 secs to fetch one epoch
    # 32 workers: 260 secs and +350G RAM for init, 0.3 secs to fetch one epoch (but have many connect err)
    # 64 workers: 560 secs and +800G RAM for init, fetch epoch failed because of leaked semaphore (have many conenct err)

    # changed to pd dataframe, 5GB RAM used in the node before launch data loader:
    # 16 worker, 105 secs and +200G RAM for init, 5.8 secs to featch one epoch
    # 32 worker, 200 secs and +300G RAM for init, 0.6 secs to fetch one epoch (but have many connect err)
    use: True
    retries: 3
    partition_key: "key"
  - stage: preliminary
    id: 1
    task: class_to_image
    data_name: imagenet-1k
    source: mongodb
    batch_size: 8
    image_size: 256
    num_workers: 8
    split: train
    partition_key: 'key'
    use: True

model:
    vae:
        pretrained_model_name_or_path: '/jfs/checkpoints/models--tencent--HunyuanVideo/snapshots/2a15b5574ee77888e51ae6f593b2ceed8ce813e5/vae'
        enable_tiling: true
        enable_slicing: true
    plan_transformer:
        dim: 3072
        ffn_dim_multiplier: 1.0
        multiple_of: 256
        n_heads: 24
        n_kv_heads: 8
        n_layers: 28 
        vocab_size: 128256  
        text_seqlen: 128 
        pre_trained_path: /jfs/checkpoints/Llama-3.2-3B/original/consolidated.00.pth
        norm_eps: 1e-5
    tokenizer:
        model_path: /jfs/checkpoints/Llama-3.2-3B/original/tokenizer.model