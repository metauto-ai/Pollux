# Template config, need to change dump_dir, data.root_dir and data.tokenizer.path
# torchrun --standalone --nnodes 1 --nproc-per-node 4 -m apps.main.train config=apps/main/configs/debug.yaml

name: "ImageNet_1B_BaseLine_256_Flux_LLAMA_Pre_Train_v0.4_debug" 
output_dir: "/mnt/data/dump"
dump_dir: "" # Mingchen: No need to put now! I revise the code to flexible put `/mnt/data/dump` + name for dump_dir
steps: 100000
seed: 777
optim:
    lr: 1.4e-4
    warmup: 2000
    lr_min_ratio: 0.000001
    clip: 10.0

env:
    ENABLE_INTRA_NODE_COMM: '0' # disable one default seeting here, as have some error in our cluster

distributed:
    fsdp_type: full_shard
    dp_shard: 4
    dp_replicate: 1
    compile: True
    model_dtype: bf16
    matmul_allow_tf32: false
    selective_activation_checkpointing: false
    tp_size: 1
    compile_cache_size_limit: 64
model:
    vae:
        pretrained_model_name_or_path: 'black-forest-labs/FLUX.1-dev'
    scheduler:
        num_train_timesteps: 1000
        base_image_seq_len: 256
        base_shift: 0.5
        max_image_seq_len: 4096
        max_shift: 1.15
        shift: 3.0 # need consider 3.0 or 1.0
        weighting_scheme: 'logit_normal'
        logit_mean: 0.0
        logit_std: 1.0
        mode_scale: 1.29
    transformer:
        dim: 2048
        ffn_dim_multiplier: 1.5
        multiple_of: 256
        n_heads: 32
        n_kv_heads: 8
        n_layers: 16
        ada_dim: 2048
        patch_size: 2
        in_channels: 16
        out_channels: 16
        tmb_size: 256
        cfg_drop_ratio: 0.1
        num_classes: 1000
        max_seqlen: 1000
        pre_trained_path: /mnt/data/Llama-3.2-1B/original/consolidated.00.pth
        block_type: "language_model"
        max_condition_seqlen: 2
        attn_type: "bi_causal"
data:
    root_dir: '/mnt/data/imagenet'
    batch_size: 64
    image_size: 256
    num_workers: 8
    split: 'train'
profiling:
    run: true

checkpoint:
    dump:
        every: 50
        keep: 1
    eval:
        every: 50
        keep: 1

logging:
    freq: 10
    wandb:
        project: "Pollux"
        entity: "metauto"
        name: ""

eval:
    name: "debug_evals"
    ckpt_dir:  ""
    dump_dir: ""
    generator:
        guidance_scale: 3.0
        dtype: bf16
        resolution: 256
        show_progress: False
        inference_steps: 25
    sample_num: 500
    eval_data:
        root_dir: '/mnt/data/imagenet'
        batch_size: 64
        image_size: 256
        num_workers: 8
        split: 'validation'