from PIL import Image
import torch
import argparse
from instruction_generation import Llama_Instruction

import os
from PIL import Image
import csv 
from tqdm import tqdm
from OmniGen import OmniGenPipeline



def parse_args():
    parser = argparse.ArgumentParser(description='Image Edit Instruction Generation', add_help=False)
    parser.add_argument('--task', type=str, default='add', help='which image edit task')
    parser.add_argument('--result_csv_file', type=str,help='path to <prompt path> csv')
    parser.add_argument('--save_path', metavar='DIR',help='path to save <prompt path> csv')
    parser.add_argument('--num_inst', type=int, default=1, help='num instruction per prompt')
    args = parser.parse_args()
    return args

def read_result_csv(csv_path):
    """
    Combine images with a same prompt as dict format
    Args:
        csv_path: the dir or file path of csv file containing data pair <prompt, image_path>
    Return: 
        dict {prompt: [image1, image2, image3],}
    """
    image_dict = {}
    if os.path.isfile(csv_path):
        with open(csv_path, mode='r', newline='', encoding='utf-8') as file:
            reader = csv.reader(file)
            for rows in reader:
                if (rows[0]) in image_dict:
                    image_dict[str(rows[0])].append(str(rows[1]))  
                else:
                    image_dict[str(rows[0])] = [str(rows[1])]

    elif os.path.isdir(csv_path):
        csv_dir_list = glob.glob(csv_path+'*.csv')
        for csv_dir in csv_dir_list:
            with open(csv_dir, mode='r', newline='', encoding='utf-8') as file:
                reader = csv.reader(file)
                for rows in reader:
                    if (rows[0]) in image_dict:
                        image_dict[str(rows[0])].append(str(rows[1]))  
                    else:
                        image_dict[str(rows[0])] = [str(rows[1])]
    return image_dict


class OmniGen():

    def __init__(self,):
        model_id = "/mnt/pollux/checkpoints/OmniGen-v1"
        self.model = OmniGenPipeline.from_pretrained(model_id)

    def generate(self, img_path, instruction, save_path):

        prompt=f"<img><|image_1|></img>\n {instruction}"

        images = self.model(
            prompt=prompt, 
            input_images=[img_path], 
            height=1024, 
            width=1024,
            guidance_scale=2.5, 
            img_guidance_scale=1.6,
            seed=222) # NOTE: If you want to edit an image generated by OmniGen's text-to-image, you must use a seed that is different from the one used to generate the original image.
        images[0].save(save_path)



def main():
    args = parse_args()
    image_dict = read_result_csv(args.result_csv_file)
    os.makedirs(args.save_path, exist_ok=True)
    csv_file = f"{args.save_path}/vargpt_edit_meta.csv"

    instruction_gen_model = Llama_Instruction()

    edit_model = OmniGen()
    for prompt, paths in tqdm(image_dict.items()):
        instructions = []
        for i in range(args.num_inst):
            instructions.append(instruction_gen_model.generate(prompt))
        print (instructions)

        for path in tqdm(paths):
            for j, instruct in enumerate(instructions):
                image_name = os.path.basename(path)[:4]
                save_path = os.path.join(args.save_path, f"{image_name}_edit_{str(j)}.png")

                edit_model.generate(path, instruct, save_path)
                row = (f"{prompt}", f"{instruct}" ,f"{path}", f"{save_path}")

                with open(csv_file, mode='a', newline='', encoding='utf-8') as file:
                    writer = csv.writer(file)
                    writer.writerow(row)


if __name__ == '__main__':
    main()
    


    ## CUDA_VISIBLE_DEVICES=7 python omnigen.py

    """
    # Environments
        conda create -n omnigen python=3.10.13
        conda activate omnigen

        # Install pytorch with your CUDA version, e.g.
        pip install torch==2.3.1+cu118 torchvision --extra-index-url https://download.pytorch.org/whl/cu118

        git clone https://github.com/VectorSpaceLab/OmniGen.git
        cd OmniGen
        pip install -e .

    # Example

    # Input

    prompt = 'a cat'
    image_path = '/mnt/pollux/wentian/image_edit/cat.png'
    instruction = [
                "add a colorful rainbow",
                "add a dog and a cat",
                "add a flying saucer",
                "Make it wear a helmet",
    ]
    model = OmniGen()

    for i, instruct in enumerate(instruction):
        save_path = f'/mnt/pollux/wentian/image_edit/cat_edit_{str(i)}.png'
        model.generate(image_path, instruct, save_path)


    # Output:
        /mnt/pollux/wentian/image_edit/cat_edit_0.png
        /mnt/pollux/wentian/image_edit/cat_edit_1.png
        /mnt/pollux/wentian/image_edit/cat_edit_2.png
        /mnt/pollux/wentian/image_edit/cat_edit_3.png
    """
